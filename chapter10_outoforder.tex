\documentclass[12pt]{article}
%\documentclass[10pt,letterpaper]{article}
\usepackage[letterpaper]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{cancel}
\usepackage{amsmath}
\usepackage{ulem}
\usepackage{authblk}
\usepackage{indentfirst}
\usepackage{enumitem}
\usepackage{cancel}
\usepackage{soul}
\newenvironment{QandA}{\begin{enumerate}[label=\bfseries\arabic*.]\bfseries}
                      {\end{enumerate}}
\newenvironment{answered}{\par\quad\normalfont}{}

\title{CIS501: Out-of-Order \\ \textit{(Dynamic Scheduling)}}
\author[1]{Shreyas S. Shivakumar}

\begin{document}

\maketitle

\section{Lecture Notes}

\begin{QandA}
\item Why do we need \textit{code scheduling} and what are the \textit{two ways} of doing it?
\begin{answered}
\vspace{-0.85cm}
\begin{itemize}
    \item We can't really avoid \textbf{load-to-use} delays in the designs that we have looked at so far. But what if we could \textbf{fill} those delay slots with instructions that are \textit{independent} of it? This way we can \textit{increase CPI} and \textit{increase ILP}. 
    \item \textbf{Static Scheduling:} at \textit{compile} time, done by software. 
    \item \textbf{Dynamic Scheduling:} at \textit{run} time, done by hardware.
    \item We will be primarily looking at \textit{dynamic scheduling}; a process that creates more opportunities to schedule things in parallel by moving independent instructions around. This is very common today and exists on cellphones, laptops, etc.
\end{itemize}
\end{answered}

\ 

\item Static Scheduling
%\vspace{-0.85cm}
\begin{answered}
Some key characteristics / criteria to properly perform \textit{static scheduling} are listed below. These must be taken care of at \textit{compile time}. 
\begin{itemize}
    \item \textbf{Scheduling Scope:} Ideally we want a larger scope because if the scope is too small there's nothing that the compiler can do to improve performance. It cannot rearrange and re-order instructions if it doesn't see enough instructions. \textit{Branch Instructions} specifically can cause problems with scheduling scope because it is impossible to move memory operations past branch instructions. 
    \item \textbf{Registers:} We need a sufficient amount of registers to hold all \textit{"live"} values. But we are limited by the ISA in how many registers are available to us. 
    \item \textbf{Alias Analysis:} We need to be able to tell whether a LOAD/STORE instruction reference the \textit{same memory locations}. This is often difficult for the compiler to do and prevents reordering of loads above stores. 
\end{itemize}

However, there are situations where \textit{Static Scheduling} works really well such as in \textbf{SAXPY} (Single-precision AX Plus Y). Since all loop iterations are independent - loop unrolling. Alias analysis is tractable. Limited registers are still a challenge. 
\end{answered}

\ 

\item Dynamic Scheduling
\begin{answered}
In this variant, the \textit{hardware} is responsible for the re-scheduling of instructions. The key motivations and criteria are similar to the ones mentioned above. We need to increase \textit{scheduling scope} and we can use \textit{branch prediction} to unroll branches. The benefit of this approach is that everything happens under the hood and the software layers are not exposed to any of the inner mechanisms. 

The \textbf{Out-of-Order Pipeline} can be divided into the following modules
\begin{itemize}
    \item \textbf{In-Order} Front End - Fetch, Decode, Rename, Dispatch
    \item \textbf{Out-of-Order} Execution - Buffer of Instruction $\rightarrow$ \{ Issue, Register Read, Execute, Write-back \} 
    \item \textbf{In-Order} Commit - Commit 
\end{itemize}

Programs will enter \textit{in-order} and exit \textit{in-order}, maintaining the illusion of sequential program execution. But between the \textit{Dispatch} and \textit{Commit} stages, the instructions can be processed out of order and hence we can reap the benefits of an out-of-order design while maintaining a final sequential ordering. 

\textbf{Dependency Types:}
\begin{itemize}
    \item \textbf{RAW} (Read After Write) - \textit{True Dependence}
    \item \textbf{WAW} (Write After Write) - \textit{False Dependence}
    \item \textbf{WAR} (Write After Read) - \textit{False Dependence}
\end{itemize}

Both \textbf{WAW} and \textbf{WAR} are \textit{False} dependencies and can be eliminated completely by \textit{Register Renaming}. The \textit{True} dependency \textbf{RAW} is enforced by the final \textit{Dynamic Scheduling}. 
\end{answered}

\ 

\item Part 1: Register Renaming
\begin{answered}
To understand the \textit{Register Renaming} algorithm, the following new ideas are required:

\textit{Q: What is the difference between architectural registers and physical registers?}

\quad In an ISA such as LC4, we have registers $R0...R8$. These are actually indirections / pointers to actual physical registers which are more than 8 in number. The pointers to the physical register locations are called \textit{architectural registers} and the actual physical locations are \textit{physical registers}.
\begin{equation*}
    \#\text{physical registers} > \#\text{architectural registers}
\end{equation*}

\textit{Q: What are the additional hardware structures required for register renaming?}

\quad The first is a \textbf{Map Table}, which maintains the mapping from \textit{architectural registers} to the \textit{physical registers}. The second is a \textbf{Free List}, which maintains the list of available registers (in a queue). 

\textit{Q: What is the goal of the Register Renaming algorithm?}

\quad The goal is to \textit{eliminate contention} / \textit{eliminate false dependencies}. 
\end{answered}

\ 

\item Part 2: Dynamic Scheduling
\begin{answered}
The previous \textit{register renaming} happened in-order, and the instructions then move onto the actual dynamic scheduling, i.e when the instructions no longer follow the program order. By this stage, all the \textit{False Dependencies} have been removed and only \textit{True Dependencies} remain. 

The instructions from the previous stage are put into a \textbf{Instruction Buffer} or \textit{Instruction Window} / \textit{Instruction Scheduler}. 

Additionally, there is another hardware structure called the \textbf{Ready Table} which maintains whether an instruction is \textit{ready} or not, and then executes the oldest \textit{ready} instruction. The ready-ness of the instruction is maintained by a single \textbf{Ready-Bit}. 

\textit{Q: Why give preference to the oldest instruction?}

\quad Old instructions will produce things that more instructions may depend on. By processing older instructions first we also guarantee that \textit{progress} will be made. 

The other key pieces of hardware are the \textbf{Issue Queue}, which is the \textit{central piece} of scheduling logic. It holds the instructions from the \textit{Dispatch Stage} to the \textit{Issue Stage}. It tracks \text{Ready} inputs as well as their \textit{Birthday} to indicate how old each instruction is. 

\textit{Q: Why maintain birthday instead of age?}

\quad Age changes over time but birthday remains consistent and is hence easier to maintain. 

\textit{Note:} The Issue Queue is not \textit{read} in program order which means that the structure itself contains instructions not in program order. This is technically not a \textit{queue} by the proper definition and works more like an Issue Table. 

The next piece of hardware is the \textbf{Re-order Buffer (ROB)}, which holds the instructions from the \textit{Fetch Stage} through to the \textit{Commit Stage}. 

In summary:
\begin{itemize}
    \item The \textit{Dispatch Stage} fills up the \textit{Issue Queue} and the \textit{Issue Stage} involves figuring out which instructions in the \textit{Issue Queue} are ready and can leave the queue to go onto the next stage.
    \item This involves \textbf{Selecting} ready instructions that can leave and \textbf{Waking Up} dependent instructions. This \textit{search} and \textit{wake-up} is done using Content Addressable Memory (CAM).
\end{itemize}  
\end{answered}

\ 

\item Register Renaming - Continued
\begin{answered}
In the previous description of the \textit{register renaming} algorithm, once a register was overwritten it was \textit{discarded}. But in reality, there is a finite number of these registers and they need to be \textbf{reused}. We can do this by \textit{tracking / logging} the overwritten registers in the \textbf{Re-Order Buffer} (ROB) and then we can \textbf{free} them after the \textbf{Commit} stage. 

\quad The only change to the algorithm is that we need to keep track of the overwritten register before updating the \textit{MapTable} with the new register. Once the instruction is finished at the \textit{Commit Stage}, we can \textbf{free} that register. 

\textbf{Re-Order Buffer (ROB):}

\begin{itemize}
    \item Holds all the information for \textit{recovery} and \textit{commit}.
    \item This information is not removed until the very last \textit{commit}.
    \item Helps track instructions for an in-order \textit{commit}.
    \item Useful in freeing up physical registers.
    \item Useful in recovering from mis-predictions. 
\end{itemize}

\textbf{Recovery:}

Everything that leaves the \textit{Commit Stage} \textbf{must be} correct. This implies that up-to the \textit{Commit Stage}, we are free to use any method of speculation and guessing, but once an instruction leaves the \textit{Commit Stage}, it affects the system permanently. This also gives us the opportunity to \textbf{recover} from mis-speculations prior to the \textit{Commit Stage}. This involves completely removing the wrong path instructions, i.e rewinding all the changed state in the system. This can be done the following ways:
\begin{itemize}
    \item Log-based Reverse Renaming - \textit{track old mapping; slow}
    \item Checkpoint-based Recovery - \textit{checkpoint MapTable and free list; more state}
    \item Hybrid - \textit{combination of both}
\end{itemize}

\textit{Note:} At the \textit{Commit Stage} the instruction becomes \textbf{Architected State}. This means that we've really made the changes and instruction has really happened. 

\textit{Q: Why is it safe to free an overwritten register?}

\quad It is safe because any instruction that requires it's value should read the new updated value and not the value that was overwritten. 
\end{answered}

\ 

\item Dynamic Scheduling - Continued
\begin{answered}
To recap, the \textit{Issue Queue} holds all waiting (un-executed) instructions. The \textit{Issue Queue} also holds ready/not-ready status of all the source registers for each instruction. 

\textit{Note:} The \textbf{Di} stage is a combination of \textit{Decode, Rename} and \textit{Dispatch}. 

The different hardware structures necessary to make this function smoothly are:
\begin{itemize}
    \item Map Table
    \item Ready Table
    \item Re-Order Buffer
    \item Issue Queue
\end{itemize}

Once a register is overwritten, it is placed in the \textbf{Re-Order Buffer} to indicate that it can be released / free-d once the instruction is complete, i.e once the instruction leaves the \textit{Commit Stage}. 

\textit{Q: Where do instructions wait?}

\quad In \textbf{In-Order} execution, instructions usually waited in the \textit{Decode Stage}. In \textbf{Out-of-Order} execution, they will need to wait too, but they can wait in more than one place such as the \textbf{Re-Order Buffer} and the \textbf{Issue Queue}. Instructions that are stalled after the \textit{Di Stage} are usually \textit{hanging out} in the \textbf{Issue Queue}.
\end{answered}

\newpage 

\item Memory Operations
\begin{answered}
So far, we have primarily looked at \textit{read} operations that use registers. What happens when we perform memory operations such as \textit{load} and \textit{store} where the actual contents of the memory are changing? 

As before, the types of dependencies are the same - \textbf{WAW} and \textbf{WAR} are \textit{False} dependencies and should be eliminated. \textbf{RAW} is a \textit{True} dependency and has to be enforced. 

\textbf{Problem:} The overall challenge is that we can't rename memory the same way that we did with registers because \textit{memory addresses are \textbf{not known} at the Rename Stage}. 
\end{answered}

\ 

\item Store Instructions
\begin{answered}
\vspace{-0.85cm}
\begin{itemize}
    \item Let's look at \textit{\textbf{only} store} instructions and ignore \textit{load} instructions for now.
    \item Store instructions write to data cache and not registers so we cannot use the \textit{register renaming} algorithm that we've seen previously. 
    \item Writing to the data cache is unrecoverable so we must be careful about what we finally write to the data cache - do it only when certain; at the \textit{Commit Stage}. 
    \item \textit{Thoughts:} Maybe put the \textit{store} instructions somewhere else?
\end{itemize}

Consider the following sequence of instructions:
\begin{center}
\begin{tabular}{ |c| } 
 \hline
 MUL P1 $\times$ P2 $\rightarrow$ P3 \\ 
 JNZ P3 \\ 
 STR P5 $\rightarrow$ [P3+4] \\
 STR P4 $\rightarrow$ [P6+8] \\
 \hline
\end{tabular}
\end{center}

\textit{Q: \textbf{Out-of-Order Stores} - What if $P3+4==P6+8$?}

\quad The two store instructions will write to the same address (WAW dependency : structural hazard). And we won't know this until the \textit{Execute Stage} because that is when the memory addresses are actually known. \textbf{Na\"ive Solution:} All stores execute in order. 

\textit{Q: \textbf{Branch Mis-prediction} - What if the JNZ instruction is mis-predicted?}

\quad We require a degree of speculation to handle branch instructions efficiently and usually on mis-speculation we can go back and re-wind to the previous steady state. But here we would have written to the \textit{data cache}, and this cannot be \textit{undone}. In this case, what if the $4^{th}$ instruction proceeded out of order (since it is independent) but then the $2^{nd}$ instruction was mis-predicted. We would need to undo the $4^{th}$ instruction. 
\end{answered}

\ 

\item Store Queue
\begin{answered}
We add another hardware structure called the \textit{Store Queue} that can solve the above two problems.
\begin{itemize}
    \item At the \textit{Dispatch Stage}, each \textit{store} instruction is given a slot in the \textit{Store Queue} and it is a FIFO queue.
    \item At the \textit{Commit Stage}, the value is read from the \textit{Store Queue} and written into the data cache.
    \item To facilitate recovery from mis-speculation, we can remove entries from the \textit{store queue}. 
    \item By introducing the \textit{Store Queue}, store instructions don't interact with the \textit{Memory Stage} at all and go to the SQ and then it is eventually committed.
\end{itemize}
\end{answered}

\ 

\item Memory Forwarding
\begin{answered}
\textit{Q: What if \textbf{load} instructions were thrown into the mix?}

Consider the following sequence of instructions:
\begin{center}
\begin{tabular}{ |c| } 
 \hline
 FDIV P1 \/ P2 $\rightarrow$ P9 \\ 
 STR P4 $\rightarrow$ [P5+4] \\
 STR P3 $\rightarrow$ [P6+8] \\
 LDR [P7] $\rightarrow$ P8 \\
 \hline
\end{tabular}
\end{center}

\textit{Q: Can LDR [P7] $\rightarrow$ P8 issue and begin executing?}

\quad Since the \textit{load} instruction could depend on the second \textit{store} instruction above, the \textit{store} instruction might not have written it's value to the data cache yet. But since the value is already ready, we should be able to pass the value to the \textit{load} instruction such as in bypassing. This is \textbf{memory forwarding}.

For the \textit{load} instruction to get the correct value, it must also search the \textit{Store Queue} in parallel with the data cache. This is different from regular \textit{register bypassing} because here we will not know the addresses until the \textit{Execute Stage}. 
\end{answered}

\

\item YOMS: Youngest Older Matching Store Policy
\begin{answered}
Consider the following sequence of instructions:
\begin{center}
\begin{tabular}{ |c| } 
 \hline
 MUL P1 $\times$ P2 $\rightarrow$ P3 \\ 
 JNZ P3 \\ 
 LDR [P3+4] $\rightarrow$ P5 \\
 STR P4 $\rightarrow$ [P6+8] \\
 \hline
\end{tabular}
\end{center}

If the $4^{th}$ instruction runs before the $3^{rd}$ instruction and if $P3+4==P6+8$ we need to ensure that the value that the \textit{load} instruction reads is not the value that was written by the \textit{store} instruction. 

\textbf{Solution:} Add an \textit{age / birthday} field to the \textit{Store Queue} entries. \textit{Load} instructions must then read from the \textbf{youngest older matching store}. 

In essence, we are preventing instructions from seeing values from the \textit{future}. 
\end{answered}

\

\item Load Scheduling
\begin{answered}
Consider the following sequence of instructions:
\begin{center}
\begin{tabular}{ |c| } 
 \hline
 MUL P1 $\times$ P2 $\rightarrow$ P3 \\ 
 JNZ P3 \\ 
 LDR [P3+4] $\rightarrow$ P5 \\
 STR P4 $\rightarrow$ [P6+8] \\
 \hline
\end{tabular}
\end{center}

If $P3+4==P6+8$, the \textit{load} instruction should get the value from the \textit{store} instruction as we've seen in the YOMS example above. \textbf{But}, the value isn't put into the \textit{Store Queue} until the store instruction has finished it's \textit{Execute Stage}. This is a \textbf{problem}. 

\textbf{Na\"ive Solution:} All loads must wait for all earlier stores. This is called \textbf{Conservative Load Scheduling}. This option is \textit{always safe} but comes at the cost of performance. 

\textit{Q: What is a better alternative to this?}

\quad Let the \textit{load} instruction do the best it can by speculation. If it is wrong, we can figure out a way to fix things. But if it is correct, we have achieved performance gains. This is called \textbf{Optimistic Load Scheduling} or \textbf{Load Speculation}.

\begin{itemize}
    \item \textit{Q: When do we speculate?} On every load!
    \item \textit{Q: How do we detect a mis-speculation?} The Store Queue can be used by the load instruction so we can check for any load instruction that ran too soon - this is done by a new piece of hardware called the \textbf{Load Queue}. 
    \item \textit{Q: How do we recover?} Squash offending load instructions and all newer instructions. The penalty here is high but it is still worth it!
\end{itemize}

\textbf{Load Queue:}

\begin{itemize}
    \item Detects load ordering violations
    \item \textit{Load Instructions:} when a load executes, write it's address into the \textit{Load Queue}.
    \item \textit{Store Instructions:} when a store executes, search the \textit{Load Queue}. 
\end{itemize}

\textbf{Load Queue vs Store Queue:}
\begin{itemize}
    \item Store Queue handles forwarding and allows out-of-order stores.
    \item Load Queue handles the detection of load ordering violations.
    \item Together they allow for aggressive load scheduling.
\end{itemize}

When this works, it \textit{increases performance} and \textit{increases ILP}. When there is a conflict the performance is worse than just waiting. The next improvement is to \textbf{avoid squashes} by predictive load scheduling. Here a PC based predictor can be used or some algorithms make predictions over sets of instructions for such dependencies. 
\end{answered}
\end{QandA}

\newpage 

\section{Textbook Notes}

\begin{QandA}
\item Register Renaming
\begin{answered}
\vspace{-0.85cm}
\begin{itemize}
    \item The goal is to eliminate dependencies that are not \textit{true} data dependencies (also called \textit{anti-dependencies}), but could either lead to potential hazards or prevent the compiler from flexibly scheduling code.
    \item Renaming registers during the unrolling process allows the compiler to move these independent instructions subsequently so as to better schedule code.
\end{itemize}
\end{answered}

\item Dynamic Scheduling
\begin{answered}
Dynamic scheduling chooses which instructions to execute in a given clock cycle while trying to avoid hazards and stalls. 

\textit{Definition:} Hardware support for reordering the order of instruction execution so as to avoid stalls. 

Conceptually, this can be thought of as the process of analyzing the data flow of a program and then executing the instructions in some order that preserves the data flow order of the program while minimizing overall stall cycles. 

Dynamic Scheduling is often extended by including hardware-based speculation, especially for branch outcomes. A speculation on load addresses allows load-store re-ordering as well, using the \textit{Commit Stage} to avoid incorrect speculations from propagating to the programmer-visible registers and memory. 
\end{answered}

\item Commit Unit
\begin{answered}
The unit in a dynamic or out-of-order execution pipeline that decides when it is safe to release the result of an operation to programmer-visible registers and memory.
\end{answered}

\item Re-order Buffer (ROB)
\begin{answered}
The buffer that holds results in a dynamically scheduled processor until it is safe to store the results to memory of a register. 
\end{answered}

\item Power Efficiency
\begin{answered}
The downside to increasing exploitation of instruction-level parallelism via dynamic multiple issue and speculation is power efficiency. 
\end{answered}
\end{QandA}
\end{document}