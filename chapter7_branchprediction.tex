\documentclass[12pt]{article}
%\documentclass[10pt,letterpaper]{article}
\usepackage[letterpaper]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{cancel}
\usepackage{amsmath}
\usepackage{ulem}
\usepackage{authblk}
\usepackage{indentfirst}
\usepackage{enumitem}
\usepackage{cancel}
\usepackage{soul}
\newenvironment{QandA}{\begin{enumerate}[label=\bfseries\alph*.]\bfseries}
                      {\end{enumerate}}
\newenvironment{answered}{\par\quad\normalfont}{}

\title{CIS501: Branch Prediction}
\author[1]{Shreyas S. Shivakumar}

\begin{document}

\maketitle

\section{Lecture Notes}

\begin{QandA}
\item Control Dependencies
\begin{answered}
    We haven't talked about \textbf{control hazards} yet, i.e when we have some control flow instruction coming through the pipeline that dictates what instruction should follow it. It can be thought of as a dependency through the \textbf{Program Counter (PC)} since the \textbf{PC} dictates the order of instruction flow. 
    
    \qquad\textbf{Branch Prediction} is how we will attempt to solve this problem. Branch Prediction cannot however fix all cases of failure related to control hazards. 
\end{answered}

\item What are the challenges with Branch instructions?
\vspace{-0.85cm}
\begin{answered}
\begin{itemize}
    \item First, when an instruction is coming down the pipeline, we first need to figure out whether it is a \textbf{BR} instruction or not. This doesn't happen during the \textit{Fetch Stage} but happens during the \textit{Decode Stage}.
    
    \item Second, we need to figure out which way the \textbf{BR} instruction should go, i.e should the processor move to the next sequential instruction or should it jump to the \textit{target}. This usually involves some computation to figure out what the \textit{target} address is, and thus involves the \textbf{ALU}. So this starts to illustrate that some of the information that we need is computed later into the pipeline.
    
    This gap between \textit{when I need the information} and \textit{when I have it} is the primary problem here and indicates that there will probably be some \textbf{stalling} involved.
    
    \item Lastly, building upon the first challenge - when the processor is handling a Branch instruction, it is usually Fetched and then moves onto the \textit{Decode Stage}. But what should we be doing in the \textit{Fetch Stage} next? Logically, we will have to fetch the next instruction in the sequence. But if the previous instruction was indeed a \textbf{Branch} instruction, we should be going to the \textit{target} in the next cycle instead of the next sequential instruction. This is another fundamental problem in handling \textbf{Branch} instructions. \textit{We don't yet know what the right thing to do is, but we have to do something!}. We can \textit{not do anything} but that would then indicate a 3 cycle stall/gap, which isn't good for performance.
\end{itemize}
\end{answered}

\item How do we then fix this problem?
\begin{answered}
    We can just \textbf{guess}. In our previous approach of handling \textit{data hazards}, we would try to identify a problem early on and make arrangements to avoid that problem or minimize it's effects on the system. However, with \textit{control hazards}, we take a different approach because \textbf{waiting/stalling} is too expensive. We instead \textbf{guess}, and hope to make a \textbf{smart guess}. This does not guarantee that we are always correct, so when we are wrong we must ensure there are mechanisms in place to clean up behind us. This is the idea behind \textbf{Speculative Execution}.
\end{answered}

\item Speculative Execution
\vspace{-0.85cm}
\begin{answered}
\begin{itemize}
    \item Execute before all parameters are known with certainty
    \item If your speculation is \textit{correct}, you have avoided stalls and improved performance significantly
    \item If your speculation is \textit{incorrect} (mis-speculation), you have to fix what you broke by flushing all incorrect instructions and undo all incorrect changes, going back to the original state
\end{itemize}
\end{answered}

\item Control Speculation
\begin{answered}
    This is the first type of speculation we will introduce. When you have a control flow instruction, you don't know where it is going, so the speculation is made on the control flow path. 
    \begin{itemize}
        \item We want to guess whether it is a \textbf{Branch Instruction} to begin with.
        \item If it is a \textit{Branch Instruction}, we want to guess whether it is \textbf{taken}.
        \item If it is \textit{taken}, we want to guess what it's \textbf{target} is.
    \end{itemize}
    This ultimately results in guessing \textit{where should I go next} or more simply \textit{what is the next \textbf{PC} that I should be going to?}
    
    According to this, what we've been doing so far is also technically \textit{speculation}, except we guessed that the next \textbf{PC} would always be \textbf{PC + 4}.
\end{answered}

\item At what stage should we perform Branch Prediction?
\begin{answered}
    Ideally, the later we do it, the more accurate our prediction will be since we will have more and more information available to us as we go down the pipeline. But this is not necessarily good for performance since it will ensure that some cycles are lost in case the branch was actually taken.
    
    \textbf{1. During Decode:}
    
    \textit{Pros:}
    
    If we do it after the decoding operation, we have a lot more information - we know if it is indeed a \textit{Branch Instruction} or a \textit{Jump Instruction} etc. This will help quite a bit for example if it is a \textit{Jump Instruction}, we know that it is always taken and we can update our PC accordingly. Even if it is a simple \textit{Add Instruction}, it is useful because then we don't need to make any exotic guesses and we can just update the PC to the next sequential address. 
    
    \textit{Cons:}
    
    Even at it's best, this will introduce a one cycle penalty. 
    \begin{center}
    \begin{tabular}{ |c|c|c|c|c|c|c|c|c|c| } 
     \hline
     Cycle & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9\\ 
     \hline
     BNEZ R3, target & F & D & X & M & W & - & - & - & -\\ 
     target: ADD R5, R4 $\rightarrow$ R4 & - & ? & F & D & X & M & W & - & - \\ 
     \hline
    \end{tabular}
    \end{center}   
    
    \textbf{2. During Fetch:}
    
    \textit{How would this work?}
    
    Realistically, we don't really know anything about the instruction during the \textit{Fetch Stage}. But we will design mechanisms that will make this possible.
\end{answered}

\item Branch Recovery
\begin{answered}
    How do we handle recovering from when a \textit{Branch Instruction} is actually \textbf{taken}, i.e we figured this out in the \textit{Execute Stage}? The instructions that are in the \textit{Fetch Stage} and the \textit{Decode Stage} are now \textbf{wrong}. These instructions need to be \textit{flushed}; this can be done by replacing them with \textbf{no-ops}. Not too much damage has been done since these instructions haven't written anything to permanent state elements (register files, memory) yet. The \textit{Program Counter} has however changed, but this is easier to fix. This exercise does introduce a \textbf{two cycle penalty} for any \textit{Branch Instruction} that is \textbf{taken}. 
    
    For \textit{example:} in \textbf{Lab 4} where we implement a Pipelined LC4 processor without \textit{Branch Instructions}, we always predict PC = PC + 1, but when this is wrong, we need to perform branch recovery and introduce the respective stall cycles. This is done by just adding a MUX that can switch between a \textit{no-op} signal and the regular instruction. 
    
    \textit{Speculation:}
    
    \begin{center}
    \begin{tabular}{ |c|c|c|c|c|c|c|c|c|c| } 
     \hline
     Cycle & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9\\ 
     \hline
     ADDI R1, 1 $\rightarrow$ R3 & F & D & X & M & W & - & - & - & -\\ 
     BNEZ R3, targ & - & F & D & \textbf{\underline{X}} & M & W & - & - & - \\ 
     STORE R6 $\rightarrow$ [R7, 4] & - & - & \textit{F} & \textit{D} & \textit{X} & \textit{M} & \textit{W} & - & - \\ 
     MUL R8, R9 $\rightarrow$ R10 & - & - & - & \textit{F} & \textit{D} & \textit{X} & \textit{M} & \textit{W} & - \\ 
     \hline
    \end{tabular}
    \end{center}       
    
    We realize where we are actually heading in \textit{Cycle 4}!
    
    \textit{Recovery:}
    \begin{center}
    \begin{tabular}{ |c|c|c|c|c|c|c|c|c|c| } 
     \hline
     Cycle & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9\\ 
     \hline
     ADDI R1, 1 $\rightarrow$ R3 & F & D & X & M & W & - & - & - & -\\ 
     BNEZ R3, targ & - & F & D & \textbf{\underline{X}} & M & W & - & - & - \\ 
     \st{STORE R6 $\rightarrow$ [R7, 4]}& - & - & \textit{\st{F}} & \textit{\st{D}} & -- & -- & -- & - & - \\ 
     \st{MUL R8, R9 $\rightarrow$ R10} & - & - & - & \textit{\st{F}} & -- & -- & -- & -- & - \\ targ: ADD R4, R5 $\rightarrow$ R4 & - & - & - & - & F & D & X & M & W \\
     \hline
    \end{tabular}
    \end{center}       
\end{answered}

\item Branch Performance
\begin{answered}
    Instructions are Branch: 20\%, Load: 20\%, Store: 10\%, Other: 50\%. 75\% of \textit{Branch Instructions} are taken. What is the CPI?
    
    \begin{equation*}
        CPI = 1 + 20\% \times 75\% \times \textbf{2}
    \end{equation*}
    \begin{equation*}
        CPI = 1 + 0.20 \times 0.75 \times \textbf{2} = 1.3
    \end{equation*}
    
    The \textbf{2} is because of the \textbf{2 cycle penalty} associated with branch mis-prediction.
    
    In this case, \textit{Branch Instructions} will cause a 30\% slow-down. We should be able to improve this if we do something a little less na\"ive than just assuming the \textit{Branch} is \textbf{not taken} each time. 
\end{answered}

\item Dynamic Branch Prediction
\begin{answered}
    Here the hardware \textbf{guesses} the outcome and starts to \textit{Fetch} from the guessed address. If this results in a mis-prediction, we can \textit{flush} instructions as seen above. This hardware exists in the \textit{Fetch Stage}, sitting concurrently with the \textit{Program Counter} register and it's incrementing hardware. 

    \textit{Dynamic Branch Prediction Performance:}

    Instructions are Branch: 20\%, Load: 20\%, Store: 10\%, Other: 50\%. 75\% of \textit{Branch Instructions} are taken. \textbf{Branch targets are predicted with 95\% accuracy}. What is the CPI?
    
    \begin{equation*}
        CPI = 1 + 20\% \times 5\% \times \textbf{2}
    \end{equation*}
    \begin{equation*}
        CPI = 1 + 0.20 \times 0.05 \times \textbf{2} = 1.02
    \end{equation*}

    In this case, \textit{Branch Instructions} will cause a 2\% slow-down. This is significantly better than the previous na\"ive approach. 
\end{answered}

\item Dynamic Branch Prediction Components
\vspace{-0.85cm}
\begin{answered}
\begin{enumerate}
    \item Is it a \textbf{branch}?
    \item Is the branch \textbf{taken} or \textbf{not taken}?
    \item If it is taken, \textbf{where} does it go?
\end{enumerate}
We need to be able to answer all these three questions \textit{speculatively}, and early on in the pipeline.

A structure called the \textbf{Branch Target Buffer (BTB)} will be used to answer part (a) and (c) of our problem above. 

A \textbf{Direction Predictor} structure will be used to answer (b). Historically, part (b) is the most challenging part of this problem and is most often associated with literature on \textit{dynamic branch prediction}.

Things to keep in mind while navigating through the mess that is \textit{branch prediction}:
\begin{itemize}
    \item Which instruction are we trying to make predictions about? The instruction \textbf{ahead} of us in the pipeline; and this is recursively applied. 
    \item Our notion of PC must now account for this since there are 5 instructions in the pipeline and they all have \textit{Program Counters}. 
\end{itemize}

\end{answered}

\item Branch Target Prediction
\begin{answered}
This will help us answer \textbf{(c) If a branch is taken, where does it go?}

\textbf{Gist:} \textit{Learn from the past, predict the future}. Disclaimer: Learn is a bit too strong a word, and \textit{memorize} is more in line with what actually occurs.

\textbf{Branch Target Buffer (BTB):}
\begin{itemize}
    \item Working: \textit{"The last time that Branch X was taken, it went to address Y; so the next time if address X is fetched, the next address to be fetched is address Y."}
    \item The BTB can be thought of as a \textit{hash table / table} that uses a fixed number of bits from a \textit{Program Counter} to index \textbf{target addresses}. For \textit{example:}, if bits 2$...$9 (7 bits) are used as index bits, we can keep track of $2^{7}$ target addresses. This also hints at why we don't use the entire PC as an index to the BTB - if you had 32-bits, that would result in $2^{32}$ target address - which would result in extremely high accuracy / precision of prediction, but require an unreasonable amount of hardware storage. Using 7-bits might not result in extremely high accuracy but this is ok since these are \textit{predictions} anyway.
    \item \textit{Aliasing} - two PCs with the same 7-bits are also possible, but this conflict is fine since we're just doing our best at making predictions anyway and we have no guarantees of perfect performance.
\end{itemize}

The \textit{Branch Target Buffer (BTB)} does exist on the critical path and therefore adds a bit of extra overhead to the overall system. 
\end{answered}

\item Branch Target Buffer Example
\begin{answered}
These screenshots were taken from the \textit{http://comparchviz.com} tool.

The following \textit{example} (Figure \ref{btb001} - Figure \ref{btb007}) assumes a 1-bit \textit{Branch Target Buffer} index, which means it has a capacity to learn $2^{1}$ target addresses and can be indexed by PC index bits $00$ and $01$.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.7\textwidth]{chapter7_imgs/btb/btb000.png}
\caption{Branch Target Buffer is empty.}
\label{btb001}
\end{figure}

\begin{figure}[!ht]
\centering
\includegraphics[width=0.7\textwidth]{chapter7_imgs/btb/btb001.png}
\caption{Tag-mismatch since the BTB was previously empty with tag bits $00$.}
\label{btb002}
\end{figure}

\begin{figure}[!ht]
\centering
\includegraphics[width=0.7\textwidth]{chapter7_imgs/btb/btb002.png}
\caption{BTB is updated with previous \textit{tag} and \textit{target}.}
\label{btb003}
\end{figure}

\begin{figure}[!ht]
\centering
\includegraphics[width=0.7\textwidth]{chapter7_imgs/btb/btb003.png}
\caption{Next instruction arrives.}\
\label{btb004}
\end{figure}

\begin{figure}[!ht]
\centering
\includegraphics[width=0.7\textwidth]{chapter7_imgs/btb/btb004.png}
\caption{Mis-prediction because BTB is empty. Target is updated after this cycle.}
\label{btb005}
\end{figure}

\begin{figure}[!ht]
\centering
\includegraphics[width=0.7\textwidth]{chapter7_imgs/btb/btb005.png}
\caption{Next instruction arrives.}
\label{btb006}
\end{figure}

\begin{figure}[!ht]
\centering
\includegraphics[width=0.7\textwidth]{chapter7_imgs/btb/btb006.png}
\caption{Correct branch prediction is made.}
\label{btb007}
\end{figure}

\end{answered}

\item Next thing

\end{QandA}

\newpage 


%\section{Textbook Notes}
%\begin{QandA}
%\item 
%\end{QandA}

\end{document}
